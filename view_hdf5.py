from flask import Flask, render_template, jsonify, request, send_file
import os
import h5py
import numpy as np
import cv2
import base64
import io
from PIL import Image
import json
import subprocess # New import
import atexit     # New import
import signal     # New import


app = Flask(__name__)

# --- RDT Process Management ---
rdt_process = None

def cleanup_rdt_process():
    """Ensure the RDT subprocess is terminated when the main app exits."""
    global rdt_process
    if rdt_process:
        print("Terminating RDT server process...")
        # Use os.killpg to kill the process and its children
        os.killpg(os.getpgid(rdt_process.pid), signal.SIGTERM)
        rdt_process = None
        print("RDT server process terminated.")

atexit.register(cleanup_rdt_process)
# --- End RDT Process Management ---

def get_database_folders():
    """è·å–databaseç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹"""
    database_dir = os.path.join(os.getcwd(), 'databases')
    folders = []
    
    if os.path.exists(database_dir) and os.path.isdir(database_dir):
        for item in os.listdir(database_dir):
            item_path = os.path.join(database_dir, item)
            if os.path.isdir(item_path):
                hdf5_count = count_hdf5_files(item_path)
                folders.append({
                    'name': item,
                    'path': item_path,
                    'type': 'subfolder',
                    'hdf5_count': hdf5_count
                })
    return folders

def count_hdf5_files(directory_path):
    """ç»Ÿè®¡æŒ‡å®šç›®å½•ä¸‹çš„HDF5æ–‡ä»¶æ•°é‡"""
    count = 0
    try:
        for file in os.listdir(directory_path):
            if file.endswith('.hdf5'):
                count += 1
    except:
        pass
    return count

def get_hdf5_files_from_database_folder(folder_name):
    """è·å–databaseä¸‹æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰HDF5æ–‡ä»¶"""
    database_dir = os.path.join(os.getcwd(), 'databases')
    folder_path = os.path.join(database_dir, folder_name)
    hdf5_files = []
    if os.path.exists(folder_path) and os.path.isdir(folder_path):
        try:
            for file in os.listdir(folder_path):
                if file.endswith('.hdf5'):
                    file_path = os.path.join(folder_path, file)
                    file_size = os.path.getsize(file_path)
                    hdf5_files.append({
                        'name': file,
                        'path': file_path,
                        'size': f"{file_size / 1024 / 1024:.2f} MB",
                        'folder': folder_name
                    })
        except Exception as e:
            print(f"Error reading folder {folder_path}: {e}")
    return hdf5_files


def extract_images_from_hdf5(file_path):
    """
    ä»HDF5æ–‡ä»¶ä¸­æŒ‰æ‘„åƒå¤´åˆ†ç»„æå–å›¾åƒæ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºbase64ç¼–ç ã€‚
    è¿”å›ä¸€ä¸ªä»¥æ‘„åƒå¤´åç§°ä¸ºé”®ï¼Œå›¾åƒå¸§åˆ—è¡¨ä¸ºå€¼çš„å­—å…¸ã€‚
    """
    camera_images = {}
    total_frames = 0
    try:
        with h5py.File(file_path, 'r') as f:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æˆ‘ä»¬æœŸæœ›çš„æ•°æ®ç»“æ„
            if 'observations' in f and 'images' in f['observations']:
                image_group = f['observations']['images']
                # éå†æ¯ä¸ªæ‘„åƒå¤´çš„æ•°æ®é›† (ä¾‹å¦‚ 'cam_wrist', 'cam_right_high')
                for cam_name in image_group.keys():
                    camera_images[cam_name] = []
                    img_data = image_group[cam_name][:]
                    
                    # è®°å½•å¸§æ•°ï¼Œæˆ‘ä»¬å‡è®¾æ‰€æœ‰æ‘„åƒå¤´çš„å¸§æ•°ç›¸åŒ
                    if total_frames == 0:
                        total_frames = len(img_data)

                    for i, img_bytes in enumerate(img_data):
                        # å¤„ç†å›¾åƒæ•°æ®
                        if isinstance(img_bytes, np.bytes_):
                            img_bytes = img_bytes.item()
                        
                        nparr = np.frombuffer(img_bytes, np.uint8)
                        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                        if img is not None:
                            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            pil_img = Image.fromarray(img_rgb)
                            buffer = io.BytesIO()
                            pil_img.save(buffer, format='JPEG', quality=85)
                            img_base64 = base64.b64encode(buffer.getvalue()).decode()
                            camera_images[cam_name].append({
                                'index': i,
                                'data': f"data:image/jpeg;base64,{img_base64}",
                            })
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†ç»“æ„ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„ç»“æ„
            elif 'images' in f:
                # ç›´æ¥åœ¨æ ¹imagesç»„ä¸­æŸ¥æ‰¾
                image_group = f['images']
                for cam_name in image_group.keys():
                    camera_images[cam_name] = []
                    img_data = image_group[cam_name][:]
                    
                    if total_frames == 0:
                        total_frames = len(img_data)

                    for i, img_bytes in enumerate(img_data):
                        if isinstance(img_bytes, np.bytes_):
                            img_bytes = img_bytes.item()
                            
                        nparr = np.frombuffer(img_bytes, np.uint8)
                        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                        if img is not None:
                            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            pil_img = Image.fromarray(img_rgb)
                            buffer = io.BytesIO()
                            pil_img.save(buffer, format='JPEG', quality=85)
                            img_base64 = base64.b64encode(buffer.getvalue()).decode()
                            camera_images[cam_name].append({
                                'index': i,
                                'data': f"data:image/jpeg;base64,{img_base64}",
                            })
    except Exception as e:
        print(f"Error processing HDF5 file: {e}")
    # æ³¨æ„è¿”å›å€¼çš„å˜åŒ–
    return camera_images, total_frames

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('front_end.html')

@app.route('/api/database_folders')
def get_database_folders_api():
    """è·å–databaseç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹åˆ—è¡¨çš„API"""
    folders = get_database_folders()
    return jsonify(folders)

from flask import send_from_directory

@app.route('/materials/<path:filename>')
def materials_files(filename):
	return send_from_directory(os.path.join(app.root_path, 'materials'), filename)

@app.route('/api/database_files/<folder_name>')
def get_database_files(folder_name):
    """è·å–databaseä¸‹æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„HDF5æ–‡ä»¶çš„API"""
    files = get_hdf5_files_from_database_folder(folder_name)
    return jsonify(files)

# This function is not used by the new UI flow, but kept for potential future use
def get_directories():
    """è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•"""
    # This function seems unused by the provided front-end logic, but we keep it.
    current_dir = os.getcwd()
    directories = [{'name': 'å½“å‰ç›®å½•', 'path': current_dir, 'type': 'current'}]
    for item in os.listdir(current_dir):
        item_path = os.path.join(current_dir, item)
        if os.path.isdir(item_path):
            directories.append({'name': item, 'path': item_path, 'type': 'subdir'})
    return directories

@app.route('/api/process_hdf5', methods=['POST'])
def process_hdf5():
    """å¤„ç†HDF5æ–‡ä»¶å¹¶æŒ‰æ‘„åƒå¤´åˆ†ç»„è¿”å›å›¾åƒæ•°æ®"""
    data = request.get_json()
    file_path = data.get('file_path')
    if not file_path or not os.path.exists(file_path):
        return jsonify({'error': 'File not found'}), 404
    
    # è·å–æ–°çš„æ•°æ®ç»“æ„
    camera_images, total_frames = extract_images_from_hdf5(file_path)
    
    # åœ¨è¿”å›çš„JSONä¸­åŒ…å«æ–°çš„æ•°æ®ç»“æ„
    return jsonify({
        'success': True, 
        'camera_images': camera_images, 
        'total_frames': total_frames,
        'camera_names': list(camera_images.keys()) # åŒæ—¶è¿”å›æ‘„åƒå¤´åç§°åˆ—è¡¨
    })

# ... æ–‡ä»¶çš„å…¶ä½™éƒ¨åˆ† (åŒ…æ‹¬ start_rdt_server) ä¿æŒä¸å˜ ...

# --- NEW API Endpoints for RDT Server ---

# æ–‡ä»¶è·¯å¾„: utils/Intergrated_interface_system/view_hdf5.py

@app.route('/api/start_rdt_server', methods=['POST'])
def start_rdt_server():
    """
    å®Œå…¨æ¨¡æ‹Ÿ inference_ym.sh çš„è¡Œä¸ºæ¥å¯åŠ¨RDTæœåŠ¡ã€‚
    ä½¿ç”¨æ­£ç¡®çš„ç›¸å¯¹è·¯å¾„å’Œå·¥ä½œç›®å½•ã€‚
    """
    global rdt_process
    
    if rdt_process and rdt_process.poll() is None:
        return jsonify({'status': 'already_running', 'message': 'RDTæœåŠ¡å·²ç»åœ¨è¿è¡Œä¸­ã€‚'})

    try:
        # åŠ¨æ€è®¡ç®—é¡¹ç›®æ ¹ç›®å½•ï¼Œè¿™å¯¹äºä½¿ç”¨ç›¸å¯¹è·¯å¾„è‡³å…³é‡è¦
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
        
        # RDT_server_stream.py çš„å®Œæ•´è·¯å¾„
        script_full_path = os.path.join(current_dir, 'RDT_server_stream.py')

        # --- ä»æ‚¨çš„ inference_ym.sh æ–‡ä»¶ä¸­æå–çš„æ­£ç¡®é…ç½® ---
        model_path_relative = "checkpoints/rdt-hans-V2/checkpoint-10000"
        lang_embeddings_path_relative = "outs/Gripper_Placement_on_Material_Tray.pt"
        ctrl_freq_val = "25"
        # ---------------------------------------------------

        # éªŒè¯è·¯å¾„åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨ (å¯é€‰ä½†æ¨èçš„å®‰å…¨æ£€æŸ¥)
        if not os.path.exists(os.path.join(project_root, model_path_relative)):
             error_msg = f"å¯åŠ¨å¤±è´¥: åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰¾ä¸åˆ°æ¨¡å‹è·¯å¾„: {model_path_relative}"
             return jsonify({'status': 'error', 'message': error_msg}), 400
        if not os.path.exists(os.path.join(project_root, lang_embeddings_path_relative)):
             error_msg = f"å¯åŠ¨å¤±è´¥: åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰¾ä¸åˆ°è¯­è¨€åµŒå…¥è·¯å¾„: {lang_embeddings_path_relative}"
             return jsonify({'status': 'error', 'message': error_msg}), 400

        # æ„å»ºä¸ inference_ym.sh å®Œå…¨ä¸€è‡´çš„å‘½ä»¤
        command = [
            'python', 
            script_full_path,
            '--pretrained_model_name_or_path', model_path_relative,
            '--lang_embeddings_path', lang_embeddings_path_relative,
            '--ctrl_freq', ctrl_freq_val
        ]
        
        # å…³é”®ï¼šè®¾ç½®å·¥ä½œç›®å½•ä¸ºé¡¹ç›®æ ¹ç›®å½•ï¼Œè®©ç›¸å¯¹è·¯å¾„ç”Ÿæ•ˆ
        rdt_process = subprocess.Popen(
            command, 
            preexec_fn=os.setsid,
            cwd=project_root
        )
        
        print(f"Successfully started RDT server with command: {' '.join(command)}")
        return jsonify({'status': 'started', 'message': 'RDTæœåŠ¡å·²æ ¹æ®æ‚¨çš„é…ç½®æˆåŠŸå¯åŠ¨ã€‚'})
        
    except Exception as e:
        print(f"Failed to start RDT server: {e}")
        return jsonify({'status': 'error', 'message': f'å¯åŠ¨å¤±è´¥: {e}'}), 500

@app.route('/api/stop_rdt_server', methods=['POST'])
def stop_rdt_server():
    """Stops the running RDT server subprocess."""
    global rdt_process
    if not rdt_process or rdt_process.poll() is not None:
        rdt_process = None
        return jsonify({'status': 'not_running', 'message': 'RDTæœåŠ¡æœªåœ¨è¿è¡Œã€‚'})
        
    try:
        print(f"Stopping RDT server with PID: {rdt_process.pid}")
        # Kill the entire process group started with setsid
        os.killpg(os.getpgid(rdt_process.pid), signal.SIGTERM)
        rdt_process.wait() # Wait for the process to terminate
        rdt_process = None
        return jsonify({'status': 'stopped', 'message': 'RDTæœåŠ¡å·²æˆåŠŸç»ˆæ­¢ã€‚'})
    except Exception as e:
        print(f"Error stopping RDT server: {e}")
        return jsonify({'status': 'error', 'message': f'ç»ˆæ­¢å¤±è´¥: {e}'}), 500

# --- End of NEW API Endpoints ---
def start_ngrok_tunnel():
    """å¯åŠ¨ ngrok å…¬ç½‘éš§é“"""
    try:
        # è¿æ¥éš§é“åˆ° 5000 ç«¯å£
        public_url = ngrok.connect(5000).public_url
        print("\n" + "="*60)
        print(f"ğŸŒ Ngrok éš§é“å·²å¯åŠ¨!")
        print(f"ğŸ”— å…¬ç½‘åœ°å€: {public_url}")
        print(f"ğŸ“¤ ä¸Šä¼ æ¥å£: {public_url}/api/upload_chunk")
        print(f"ğŸ”„ åˆå¹¶æ¥å£: {public_url}/api/merge_chunks")
        print("="*60 + "\n")
        
        # ä¿å­˜å…¬ç½‘åœ°å€åˆ°æ–‡ä»¶
        with open("public_url.txt", "w") as f:
            f.write(f"æœåŠ¡å™¨å…¬ç½‘åœ°å€: {public_url}\n")
            f.write(f"ä¸Šä¼ åˆ†å—: POST {public_url}/api/upload_chunk\n")
            f.write(f"åˆå¹¶æ–‡ä»¶: POST {public_url}/api/merge_chunks\n")
        
        return public_url
    except Exception as e:
        print(f"âŒ å¯åŠ¨ ngrok å¤±è´¥: {e}")
        print("â„¹ï¸  è¯·æ£€æŸ¥: 1) æ˜¯å¦å®‰è£… pyngrok, 2) ç½‘ç»œè¿æ¥")
        return None
if __name__ == '__main__':
	start_ngrok_tunnel()
    app.run(debug=True, host='0.0.0.0', port=5000)
